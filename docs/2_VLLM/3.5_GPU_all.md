## Khi d√πng `--gpus all` th√¨ sao:

### üéØ **√ù nghƒ©a:**
- Container c√≥ th·ªÉ **access t·∫•t c·∫£ GPU** (0, 1, 2)
- vLLM s·∫Ω **t·ª± ch·ªçn GPU** ƒë·ªÉ ch·∫°y (th∆∞·ªùng GPU c√≥ nhi·ªÅu memory tr·ªëng nh·∫•t)

### ü§ñ **vLLM behavior v·ªõi multiple GPUs:**

**1. Single GPU selection:**
- vLLM **m·∫∑c ƒë·ªãnh ch·ªâ d√πng 1 GPU** cho model nh·ªè nh∆∞ Qwen2.5-1.5B
- T·ª± ƒë·ªông ch·ªçn GPU c√≥ **nhi·ªÅu free memory** nh·∫•t
- Trong case c·ªßa b·∫°n: s·∫Ω ch·ªçn **GPU 1** (8GB tr·ªëng)

**2. Tensor Parallel (n·∫øu model l·ªõn):**
- Model l·ªõn c√≥ th·ªÉ **split across multiple GPUs**
- C·∫ßn th√™m flag `--tensor-parallel-size 2` ƒë·ªÉ d√πng 2 GPUs

### ‚ö†Ô∏è **Potential Issues:**

**1. Resource Conflict:**
- N·∫øu c√≥ nhi·ªÅu processes c√πng d√πng `--gpus all`
- C√≥ th·ªÉ **conflict** khi c√πng ch·ªçn 1 GPU

**2. Memory Competition:**
- Container th·∫•y ƒë∆∞·ª£c all GPUs nh∆∞ng v·∫´n b·ªã **OOM** n·∫øu GPU b·ªã ƒë·∫ßy
- Kh√¥ng t·ª± ƒë·ªông **load balance** gi·ªØa GPUs

### üéØ **So s√°nh:**

| Flag | Behavior | Use Case |
|------|----------|----------|
| `--gpus '"device=1"'` | ‚úÖ **Specific GPU** | Ki·ªÉm so√°t ch√≠nh x√°c, tr√°nh conflict |
| `--gpus all` | ü§ñ **Auto selection** | Flexible, vLLM t·ª± ch·ªçn |

### üí° **Recommendation:**

V·ªõi setup hi·ªán t·∫°i c·ªßa b·∫°n:
```bash
--gpus '"device=1"'  # Safer choice
```

V√¨:
- GPU 1 c√≥ 8GB tr·ªëng (enough cho Qwen2.5-1.5B)
- Tr√°nh conflict v·ªõi GPU 2 (ƒëang 100% util)
- Predictable behavior

**`--gpus all`** OK n·∫øu b·∫°n mu·ªën vLLM t·ª± decide, nh∆∞ng √≠t control h∆°n!
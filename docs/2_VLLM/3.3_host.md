Ah tôi thấy vấn đề rồi! 

**Nhìn kỹ nvidia-smi:**
- GPU 2 bây giờ: **7,982 MiB used / 24,576 MiB total** (có ~16GB trống)
- Nhưng có **2 processes** đang chạy:
  - PID 78183: 7,356 MiB 
  - PID 95412: 624 MiB

**Vấn đề:** vLLM cần **memory liền kề (contiguous)** để allocate KV cache, nhưng memory bị **phân mảnh (fragmented)**.

**Solutions:**

**Option 1 - Giảm memory utilization:**
Ran tool

**Đã thêm `--gpu-memory-utilization 0.6`** (chỉ dùng 60% thay vì 90% default)

**Thử chạy lại:**
```bash
./vllm.sh
```

**Nếu vẫn lỗi, thử Option 2 - Kill process khác trên GPU 2:**

Check process nào đang dùng 7GB trên GPU 2:
```bash
ps -aux | grep 78183
```

**Option 3 - Dùng GPU 1 thay vì GPU 2:**
Ran tool

**Better choice:** Đổi lại về **GPU 1** vì:

- GPU 1: **8.4GB trống**, memory ít fragmented hơn
- GPU 2: **16.6GB trống** nhưng bị fragmented do 2 processes

**Bây giờ thử:**
```bash
./vllm.sh
```

**Summary changes:**
✅ `--gpu-memory-utilization 0.6` (chỉ dùng 60% GPU memory)  
✅ Back to **GPU 1** (ổn định hơn)

Qwen2.5-1.5B chỉ cần ~3-4GB, GPU 1 có 8.4GB trống should work!
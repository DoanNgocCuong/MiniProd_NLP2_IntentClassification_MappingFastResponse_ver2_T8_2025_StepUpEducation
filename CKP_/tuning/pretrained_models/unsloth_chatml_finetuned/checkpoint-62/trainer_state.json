{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.3846153846153846,
  "eval_steps": 500,
  "global_step": 62,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.038461538461538464,
      "grad_norm": 2.481471061706543,
      "learning_rate": 0.0,
      "loss": 4.4917,
      "step": 1
    },
    {
      "epoch": 0.07692307692307693,
      "grad_norm": 2.654755115509033,
      "learning_rate": 4e-05,
      "loss": 4.3903,
      "step": 2
    },
    {
      "epoch": 0.11538461538461539,
      "grad_norm": 2.664926767349243,
      "learning_rate": 8e-05,
      "loss": 4.5659,
      "step": 3
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 2.8926448822021484,
      "learning_rate": 0.00012,
      "loss": 4.5009,
      "step": 4
    },
    {
      "epoch": 0.19230769230769232,
      "grad_norm": 2.9310829639434814,
      "learning_rate": 0.00016,
      "loss": 4.2016,
      "step": 5
    },
    {
      "epoch": 0.23076923076923078,
      "grad_norm": 2.3146190643310547,
      "learning_rate": 0.0002,
      "loss": 3.9343,
      "step": 6
    },
    {
      "epoch": 0.2692307692307692,
      "grad_norm": 1.8763813972473145,
      "learning_rate": 0.00019649122807017543,
      "loss": 3.651,
      "step": 7
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 1.4427666664123535,
      "learning_rate": 0.00019298245614035088,
      "loss": 3.3262,
      "step": 8
    },
    {
      "epoch": 0.34615384615384615,
      "grad_norm": 1.4431560039520264,
      "learning_rate": 0.00018947368421052632,
      "loss": 3.1019,
      "step": 9
    },
    {
      "epoch": 0.38461538461538464,
      "grad_norm": 1.0724765062332153,
      "learning_rate": 0.00018596491228070177,
      "loss": 3.0057,
      "step": 10
    },
    {
      "epoch": 0.4230769230769231,
      "grad_norm": 0.9302639365196228,
      "learning_rate": 0.0001824561403508772,
      "loss": 2.8302,
      "step": 11
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.930003821849823,
      "learning_rate": 0.00017894736842105264,
      "loss": 2.676,
      "step": 12
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.899813711643219,
      "learning_rate": 0.00017543859649122806,
      "loss": 2.5466,
      "step": 13
    },
    {
      "epoch": 0.5384615384615384,
      "grad_norm": 0.8516101837158203,
      "learning_rate": 0.00017192982456140353,
      "loss": 2.5141,
      "step": 14
    },
    {
      "epoch": 0.5769230769230769,
      "grad_norm": 0.7970656156539917,
      "learning_rate": 0.00016842105263157895,
      "loss": 2.3471,
      "step": 15
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.8319860100746155,
      "learning_rate": 0.0001649122807017544,
      "loss": 2.2207,
      "step": 16
    },
    {
      "epoch": 0.6538461538461539,
      "grad_norm": 0.7610841393470764,
      "learning_rate": 0.00016140350877192982,
      "loss": 2.1389,
      "step": 17
    },
    {
      "epoch": 0.6923076923076923,
      "grad_norm": 0.7677779793739319,
      "learning_rate": 0.00015789473684210527,
      "loss": 1.9685,
      "step": 18
    },
    {
      "epoch": 0.7307692307692307,
      "grad_norm": 0.7402974367141724,
      "learning_rate": 0.0001543859649122807,
      "loss": 1.9953,
      "step": 19
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.8791191577911377,
      "learning_rate": 0.00015087719298245616,
      "loss": 1.766,
      "step": 20
    },
    {
      "epoch": 0.8076923076923077,
      "grad_norm": 0.7849948406219482,
      "learning_rate": 0.00014736842105263158,
      "loss": 1.758,
      "step": 21
    },
    {
      "epoch": 0.8461538461538461,
      "grad_norm": 0.7891480326652527,
      "learning_rate": 0.00014385964912280703,
      "loss": 1.6235,
      "step": 22
    },
    {
      "epoch": 0.8846153846153846,
      "grad_norm": 0.7674791812896729,
      "learning_rate": 0.00014035087719298245,
      "loss": 1.4706,
      "step": 23
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 0.7809515595436096,
      "learning_rate": 0.0001368421052631579,
      "loss": 1.2705,
      "step": 24
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 0.829804003238678,
      "learning_rate": 0.00013333333333333334,
      "loss": 1.3703,
      "step": 25
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.8213064074516296,
      "learning_rate": 0.0001298245614035088,
      "loss": 1.1991,
      "step": 26
    },
    {
      "epoch": 1.0384615384615385,
      "grad_norm": 0.8288954496383667,
      "learning_rate": 0.0001263157894736842,
      "loss": 1.0542,
      "step": 27
    },
    {
      "epoch": 1.0769230769230769,
      "grad_norm": 0.943483829498291,
      "learning_rate": 0.00012280701754385965,
      "loss": 0.7648,
      "step": 28
    },
    {
      "epoch": 1.1153846153846154,
      "grad_norm": 0.9387078881263733,
      "learning_rate": 0.00011929824561403509,
      "loss": 0.7021,
      "step": 29
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.9366143941879272,
      "learning_rate": 0.00011578947368421053,
      "loss": 0.9405,
      "step": 30
    },
    {
      "epoch": 1.1923076923076923,
      "grad_norm": 0.9112190008163452,
      "learning_rate": 0.00011228070175438597,
      "loss": 0.4775,
      "step": 31
    },
    {
      "epoch": 1.2307692307692308,
      "grad_norm": 0.950568437576294,
      "learning_rate": 0.00010877192982456141,
      "loss": 0.4289,
      "step": 32
    },
    {
      "epoch": 1.2692307692307692,
      "grad_norm": 0.9680048823356628,
      "learning_rate": 0.00010526315789473685,
      "loss": 0.7611,
      "step": 33
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 1.035647988319397,
      "learning_rate": 0.0001017543859649123,
      "loss": 0.5212,
      "step": 34
    },
    {
      "epoch": 1.3461538461538463,
      "grad_norm": 0.8246617913246155,
      "learning_rate": 9.824561403508771e-05,
      "loss": 0.4515,
      "step": 35
    },
    {
      "epoch": 1.3846153846153846,
      "grad_norm": 0.8387020230293274,
      "learning_rate": 9.473684210526316e-05,
      "loss": 0.4882,
      "step": 36
    },
    {
      "epoch": 1.4230769230769231,
      "grad_norm": 1.0800758600234985,
      "learning_rate": 9.12280701754386e-05,
      "loss": 0.7698,
      "step": 37
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 0.7922933101654053,
      "learning_rate": 8.771929824561403e-05,
      "loss": 0.7009,
      "step": 38
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.7217432260513306,
      "learning_rate": 8.421052631578948e-05,
      "loss": 0.1668,
      "step": 39
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.5112144351005554,
      "learning_rate": 8.070175438596491e-05,
      "loss": 0.2872,
      "step": 40
    },
    {
      "epoch": 1.5769230769230769,
      "grad_norm": 0.5588985085487366,
      "learning_rate": 7.719298245614036e-05,
      "loss": 0.577,
      "step": 41
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.572070300579071,
      "learning_rate": 7.368421052631579e-05,
      "loss": 0.5977,
      "step": 42
    },
    {
      "epoch": 1.6538461538461537,
      "grad_norm": 0.4917314946651459,
      "learning_rate": 7.017543859649122e-05,
      "loss": 0.4723,
      "step": 43
    },
    {
      "epoch": 1.6923076923076923,
      "grad_norm": 0.409681111574173,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.1942,
      "step": 44
    },
    {
      "epoch": 1.7307692307692308,
      "grad_norm": 0.42350754141807556,
      "learning_rate": 6.31578947368421e-05,
      "loss": 0.2992,
      "step": 45
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 0.3977814018726349,
      "learning_rate": 5.9649122807017544e-05,
      "loss": 0.2859,
      "step": 46
    },
    {
      "epoch": 1.8076923076923077,
      "grad_norm": 0.3444734215736389,
      "learning_rate": 5.6140350877192984e-05,
      "loss": 0.1509,
      "step": 47
    },
    {
      "epoch": 1.8461538461538463,
      "grad_norm": 0.43960878252983093,
      "learning_rate": 5.2631578947368424e-05,
      "loss": 0.5232,
      "step": 48
    },
    {
      "epoch": 1.8846153846153846,
      "grad_norm": 0.45584219694137573,
      "learning_rate": 4.912280701754386e-05,
      "loss": 0.1006,
      "step": 49
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.43225446343421936,
      "learning_rate": 4.56140350877193e-05,
      "loss": 0.5814,
      "step": 50
    },
    {
      "epoch": 1.9615384615384617,
      "grad_norm": 0.42109549045562744,
      "learning_rate": 4.210526315789474e-05,
      "loss": 0.4495,
      "step": 51
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4042242467403412,
      "learning_rate": 3.859649122807018e-05,
      "loss": 0.2447,
      "step": 52
    },
    {
      "epoch": 2.0384615384615383,
      "grad_norm": 0.4405626356601715,
      "learning_rate": 3.508771929824561e-05,
      "loss": 0.3893,
      "step": 53
    },
    {
      "epoch": 2.076923076923077,
      "grad_norm": 0.38190194964408875,
      "learning_rate": 3.157894736842105e-05,
      "loss": 0.1931,
      "step": 54
    },
    {
      "epoch": 2.1153846153846154,
      "grad_norm": 0.4114363491535187,
      "learning_rate": 2.8070175438596492e-05,
      "loss": 0.4984,
      "step": 55
    },
    {
      "epoch": 2.1538461538461537,
      "grad_norm": 0.3806432783603668,
      "learning_rate": 2.456140350877193e-05,
      "loss": 0.3395,
      "step": 56
    },
    {
      "epoch": 2.1923076923076925,
      "grad_norm": 0.315999299287796,
      "learning_rate": 2.105263157894737e-05,
      "loss": 0.1109,
      "step": 57
    },
    {
      "epoch": 2.230769230769231,
      "grad_norm": 0.5037335753440857,
      "learning_rate": 1.7543859649122806e-05,
      "loss": 0.2973,
      "step": 58
    },
    {
      "epoch": 2.269230769230769,
      "grad_norm": 0.37216517329216003,
      "learning_rate": 1.4035087719298246e-05,
      "loss": 0.1438,
      "step": 59
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.4311206042766571,
      "learning_rate": 1.0526315789473684e-05,
      "loss": 0.4482,
      "step": 60
    },
    {
      "epoch": 2.3461538461538463,
      "grad_norm": 0.37529128789901733,
      "learning_rate": 7.017543859649123e-06,
      "loss": 0.2096,
      "step": 61
    },
    {
      "epoch": 2.3846153846153846,
      "grad_norm": 0.4463407099246979,
      "learning_rate": 3.5087719298245615e-06,
      "loss": 0.5384,
      "step": 62
    }
  ],
  "logging_steps": 1,
  "max_steps": 62,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 837605132937216.0,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
